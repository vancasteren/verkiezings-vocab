{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-28 14:12:12 INFO: Loading these models for language: nl (Dutch):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | alpino  |\n",
      "| lemma     | alpino  |\n",
      "=======================\n",
      "\n",
      "2021-02-28 14:12:12 INFO: Use device: cpu\n",
      "2021-02-28 14:12:12 INFO: Loading: tokenize\n",
      "2021-02-28 14:12:12 INFO: Loading: lemma\n",
      "2021-02-28 14:12:12 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import stanza\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "nlp = stanza.Pipeline('nl', processors = 'tokenize,lemma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify data paths, etc.\n",
    "\n",
    "pdffolder = f'data'\n",
    "stopwordspath = 'data/stopwords-nl.txt'\n",
    "\n",
    "with open(stopwordspath, 'r', encoding = 'utf-8') as infile:\n",
    "    stopwords = infile.read().split()\n",
    "    \n",
    "lemmas = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text read functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_texts(pdffolder):\n",
    "    '''Import all texts from pdf-files in folder. Returns pandas Series containing texts.'''\n",
    "    programmes = dict()\n",
    "    for prog in glob.glob(f'{pdffolder}/*.pdf'):\n",
    "        party_name = prog.split('\\\\')[1].split('.')[0]\n",
    "\n",
    "        doc = fitz.open(prog)\n",
    "\n",
    "        text = ''\n",
    "        for n in range(doc.pageCount):\n",
    "            text += doc.getPageText(n)\n",
    "        programmes[party_name] = text\n",
    "    return pd.Series(programmes)\n",
    "\n",
    "def get_text(pdffile):\n",
    "    '''Reads and returns text from pdffile.'''\n",
    "    \n",
    "    doc = fitz.open(pdffile)\n",
    "\n",
    "    text = ''\n",
    "    for n in range(doc.pageCount):\n",
    "        text += doc.getPageText(n)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(party, text):\n",
    "    '''Filter headers/footers for 2021 election programmes. Returns filtered text.'''\n",
    "    \n",
    "    if party == '50PLUS':\n",
    "        text = text.replace('De kracht van PLUS \\nVerkiezingsprogramma 2021-', '')\n",
    "        text = text.replace('•', '')\n",
    "        \n",
    "    elif party == 'CDA':\n",
    "        text = text.replace('CDA-VERKIEZINGSPROGRAMMA 2021-Thuis\\nNu doorpakken', '')\n",
    "        text = text.replace('Nu doorpakken\\nCDA-VERKIEZINGSPROGRAMMA 2021', '')\n",
    "        text = text.replace('CDA-VERKIEZINGSPROGRAMMA 2021-2025', '')\n",
    "        text = text.replace('CDA-VERKIEZINGSPROGRAMMA 2021', '')\n",
    "        text = text.replace('\\nNu doorpakken\\n', '')\n",
    "        text = text.replace('Christen-Democratisch Appèl', '')\n",
    "\n",
    "    elif party == 'CU':\n",
    "        text = text.replace('CHRISTENUNIE VERKIEZINGSPROGRAMMA 2021-2025', '')\n",
    "        text = text.replace('\\nKIEZEN  VOOR WAT ECHT TELT', '')\n",
    "        text = text.replace('ChristenUnie', '')\n",
    "        \n",
    "    elif party == 'D66':\n",
    "        text = text.replace('Verkiezingsprogramma 2021 - 2025                   \\n  De digitale versie lees je op d66.nl/eennieuwbegin', '')\n",
    "        text = text.replace('Een nieuw begin - Laat iedereen vrij, maar niemand vallen.', '')\n",
    "        text = text.replace(\"Democraten '66\", '')\n",
    "        \n",
    "    elif party == 'DENK':\n",
    "        text = text.replace('Verkiezingsprogramma DENK 2021 – 2025', '')\n",
    "        \n",
    "    elif party == 'FVD':\n",
    "        text = text.replace('FVD Verkiezingsprogramma 2021-2025', '')\n",
    "        text = text.replace('Forum voor Democratie', '')\n",
    "        \n",
    "    elif party == 'GL':\n",
    "        text = text.replace('VERKIEZINGSPROGRAMMA GROENLINKS 2021', '')\n",
    "        text = text.replace('GROENLINKS', '')\n",
    "        text = text.replace('GroenLinks', '')\n",
    "        \n",
    "    elif party == 'PvdA':\n",
    "        text = text.replace('Verkiezingsprogramma PvdA 2021-2025', '')\n",
    "        text = text.replace('•', '')\n",
    "        text = text.replace('Partij van de Arbeid', '')\n",
    "        \n",
    "    elif party == 'PvdD':\n",
    "        text = text.replace('VERKIEZINGSPROGRAMMA PARTIJ VOOR DE DIEREN TWEEDE KAMERVERKIEZINGEN 2021\\nVERKIEZINGSPROGRAMMA PARTIJ VOOR DE DIEREN TWEEDE KAMERVERKIEZINGEN 202', '')\n",
    "        text = text.replace('Partij voor de Dieren', '')\n",
    "        \n",
    "    elif party == 'PVV':\n",
    "        text = text.replace('Het gaat om u\\nVerkiezingsprogramma PVV 2021 - 2025', '')\n",
    "        text = text.replace('Verkiezingsprogramma PVV 2021 - 2025\\nHet gaat om u', '')\n",
    "        text = text.replace('Partij voor de Vrijheid', '')\n",
    "    \n",
    "    #SGP hoeft niet te worden schoongemaakt (geen voettekst).\n",
    "        \n",
    "    elif party == 'SP':\n",
    "        text = text.replace('VERKIEZINGSPROGRAMMA VAN DE SP 17 MAART 2021 STEL EEN DAAD', '')\n",
    "        text = text.replace('Socialistische Partij', '')\n",
    "\n",
    "    elif party == 'VVD':\n",
    "        #hoofdstuktitels in voettekst\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Ons nieuwe verhaal', '')\n",
    "        text = text.replace('▶', '')\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Klimaat en Duurzaamheid','')\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Economie en Ondernemen','')\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Werk en Zekerheid','')\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Onderwijs en Vrijheid','')\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Volksgezondheid en Zorg','')\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Buitenland en Defensie','')\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Migratie en Integratie','')\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Veiligheid', '')\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Wonen en Vervoer', '')\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Landbouw en Natuur', '')\n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025  -  Overheid en Democratie', '')\n",
    "        text = text.replace('Volkspartij voor Vrijheid en Democratie', '')        \n",
    "        text = text.replace('Verkiezingsprogramma 2021 -2025', '')\n",
    "        \n",
    "    text = text.replace(party, '')\n",
    "    \n",
    "    for t in set(re.findall(' ?\\n[0-9]+', text)):\n",
    "        text = text.replace(t, '')\n",
    "    for t in set(re.findall('[0-9]+ \\n•?', text)):\n",
    "        text = text.replace(t, '')\n",
    "        \n",
    "    for t in set(re.findall('[0-9]', text)):\n",
    "        text = text.replace(t, '')\n",
    "    \n",
    "    return text\n",
    "\n",
    "def filter_text17(party, text):\n",
    "    '''Filter headers/footers for 2017 election programmes. Returns filtered text.'''\n",
    "    \n",
    "    party = party.replace('-2017', '')\n",
    "    \n",
    "    if party == 'CDA':\n",
    "        text = text.replace('CDA VERKIEZINGSPROGRAM 2017-2021', '')\n",
    "        text = text.replace('Christen-Democratisch Appèl', '')\n",
    "        \n",
    "    if party == 'CU':\n",
    "        text = text.replace('Verkiezingsprogramma 2017-2021', '')\n",
    "        text = text.replace('ChristenUnie', '')\n",
    "        \n",
    "    if party == 'D66':\n",
    "        text = text.replace(\"Democraten '66\", '')\n",
    "        \n",
    "    if party == 'DENK':\n",
    "        text = text.replace('verkiezingsprogramma 2017-2021', '')\n",
    "        text = text.replace('Verkiezingsprogramma DENK 2017-2021', '')\n",
    "        \n",
    "    if party == 'FVD':\n",
    "        text = text.replace('Forum voor Democratie', '')\n",
    "        \n",
    "    if party == 'GL':\n",
    "        text = text.replace('GROENLINKS', '')\n",
    "        text = text.replace('GroenLinks', '')    \n",
    "        \n",
    "    if party == 'PvdA':\n",
    "        text = text.replace('•', '')\n",
    "        text = text.replace('EEN VERBONDEN SAMENLEVING', '')\n",
    "        text = text.replace('Partij van de Arbeid', '')\n",
    "    \n",
    "    if party == 'PvdD':\n",
    "        text = text.replace('Verkiezingsprogramma Partij voor de Dieren Tweede Kamerverkiezingen 2017', '')\n",
    "        text = text.replace('Partij voor de Dieren', '')\n",
    "        \n",
    "    if party == 'PVV':\n",
    "        text = text.replace('CONCEPT - VERKIEZINGSPROGRAMMA PW 2017', '')\n",
    "        text = text.replace('Partij voor de Vrijheid', '')\n",
    "    \n",
    "    if party == 'SP':\n",
    "        text = text.replace('PROGRAMMA VOOR EEN SOCIAAL NEDERLAND', '')\n",
    "        text = text.replace('Socialistische Partij', '')\n",
    "        \n",
    "    if party == 'VVD':\n",
    "        text = text.replace('■', '')\n",
    "        text = text.replace('Volkspartij voor Vrijheid en Democratie', '')   \n",
    "         \n",
    "    text = text.replace(party, '')\n",
    "    \n",
    "    for t in set(re.findall(' ?\\n[0-9]+', text)):\n",
    "        text = text.replace(t, '')\n",
    "    for t in set(re.findall('[0-9]+ \\n•?', text)):\n",
    "        text = text.replace(t, '')\n",
    "        \n",
    "    for t in set(re.findall('[0-9]', text)):\n",
    "        text = text.replace(t, '')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_in_text(pdfpath, stopwords):\n",
    "    '''Reads text in pdf file and counts words, except stopwords.    \n",
    "    Returns frequency dict of all lemmas in the text.'''\n",
    "    doc = fitz.open(pdfpath)\n",
    "\n",
    "    text = ''\n",
    "    for n in range(doc.pageCount):\n",
    "        text += doc.getPageText(n)\n",
    "\n",
    "    with open(stopwordspath, 'r', encoding = 'utf-8') as infile:\n",
    "        stopwords = infile.read().split()\n",
    "\n",
    "    words = [w.lower() for w in nltk.word_tokenize(text) if w.lower() not in stopwords and w.isalpha() and len(w) > 1]\n",
    "    counter = dict(Counter(words))\n",
    "    return counter\n",
    "\n",
    "\n",
    "def count_lemmas_in_text(party, pdfpath, stopwords, histo = False):\n",
    "    '''Reads text in pdf file. Filters text and counts lemmas in filtered text, except stopwords.\n",
    "    If histo == True, uses filter for 2017 texts.\n",
    "    \n",
    "    Returns frequency dict of all lemmas in the text.'''\n",
    "    \n",
    "    doc = fitz.open(pdfpath)\n",
    "\n",
    "    if histo == False:\n",
    "        text = filter_text(party, get_text(pdfpath))\n",
    "    else:\n",
    "        text = filter_text17(party, get_text(pdfpath))\n",
    "        \n",
    "    document = nlp(text)\n",
    "    lemmas = [w.lower() for w in document.get('lemma') if w.isalpha() and len(w) > 1 and w.lower() not in stopwords]\n",
    "    counter = dict(Counter(lemmas))\n",
    "    return counter\n",
    "\n",
    "def analyze_programs(pdffolder, stopwords, lemmas = True, histo = False):\n",
    "    '''Wrapper function. Counts lemmas for every pdf file in pdffolder, except stopwords.\n",
    "    Returns: pd.DataFrame allemaal: counted lemmas for every text.\n",
    "    Returns: pd.DataFrame allemaal_totaal: counted lemmas for every text, including totals.\n",
    "    Returns: pd.DataFrame fractions_df: relative frequency of lemma (promille)\n",
    "    '''\n",
    "    \n",
    "    dfs = []\n",
    "    fraction_dfs = []\n",
    "    for prog in glob.glob(f'{pdffolder}/*.pdf'):\n",
    "        party_name = prog.split('\\\\')[1].split('.')[0]\n",
    "        print('processing party:', party_name)\n",
    "        if lemmas:\n",
    "            counter = count_lemmas_in_text(party_name, prog, stopwords, histo)\n",
    "        else:\n",
    "            counter = count_words_in_text(prog, stopwords)\n",
    "        df = pd.DataFrame.from_dict(counter, orient = 'index')\n",
    "        if party_name.endswith('17'):\n",
    "            df.columns = [f'{party_name[:-5]}']\n",
    "        else:\n",
    "            df.columns = [f'{party_name}']\n",
    "        dfs.append(df)\n",
    "        \n",
    "        #compute relative frequencies\n",
    "        fractions = dict()\n",
    "        wordcount = df.sum()\n",
    "        for word, count in counter.items():\n",
    "            fractions[word] = count / wordcount * 1000\n",
    "        fraction_dfs.append(pd.DataFrame.from_dict(fractions, orient = 'index'))\n",
    "\n",
    "    allemaal = pd.concat(dfs, axis = 1)\n",
    "    allemaal = allemaal.round(0).fillna(0)\n",
    "\n",
    "    word_freqs = pd.DataFrame(allemaal.sum(axis = 1), columns = ['Totaal'])\n",
    "    word_totals = allemaal.sum(axis = 0)\n",
    "    \n",
    "    \n",
    "    fractions_df = pd.concat(fraction_dfs, axis=1)\n",
    "    fractions_df = fractions_df.fillna(0)\n",
    "\n",
    "    allemaal_totaal = pd.concat([allemaal, word_freqs], axis = 1).round(0)\n",
    "    fractions_df = fractions_df.round(4)\n",
    "    return allemaal, allemaal_totaal, fractions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing party: 50PLUS\n",
      "processing party: CDA\n",
      "processing party: CU\n"
     ]
    }
   ],
   "source": [
    "allemaal, allemaal_totaal, fractions = analyze_programs(pdffolder, stopwords, lemmas = lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine(frequencies):\n",
    "    '''Computes and returns cosine frequency for every ith and jth column in the frequency table.'''\n",
    "    \n",
    "    correl = defaultdict(dict)\n",
    "    covered = []\n",
    "\n",
    "    for party1 in frequencies.columns:\n",
    "        for party2 in frequencies.columns:\n",
    "            zuiver1 = dict()\n",
    "            zuiver2 = dict()\n",
    "            terms1 = frequencies[party1].to_dict()\n",
    "            terms2 = frequencies[party2].to_dict()\n",
    "            \n",
    "            #only consider terms in one of the two texts we're comparing\n",
    "            for word, freq in terms1.items():\n",
    "                if freq + terms2[word] > 0:\n",
    "                    zuiver1[word] = freq\n",
    "                    zuiver2[word] = terms2[word]\n",
    "\n",
    "            zuiver1 = pd.Series(zuiver1)\n",
    "            zuiver1.name = party1\n",
    "            zuiver2 = pd.Series(zuiver2)\n",
    "            zuiver2.name = party2\n",
    "            \n",
    "            c = cosine_similarity([zuiver1], [zuiver2])\n",
    "            #print(party1, party2, c)\n",
    "            correl[party1][party2] = c[0][0]\n",
    "\n",
    "        covered.append(party1)\n",
    "\n",
    "    return (pd.DataFrame.from_dict(correl).T.round(3)*100).convert_dtypes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosy = compute_cosine(allemaal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate frequency tables for 2017 election programmes\n",
    "histo, histo_totaal, histo_frac = analyze_programs(f'{pdffolder}/2017', stopwords, lemmas = lemmas, histo = True)\n",
    "\n",
    "#Compute cosine similarity for 2017 programmes\n",
    "cosy_h = compute_cosine(histo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosy_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute consistency by computing cosine similarity between a party's programme in 2021 and 2017.\n",
    "\n",
    "histo = histo_totaal.drop('Totaal', axis=1)\n",
    "\n",
    "selfcorr = dict()\n",
    "\n",
    "for party in allemaal.columns:\n",
    "    nu = allemaal[party]\n",
    "    toen = histo[party]\n",
    "    samen = pd.concat([nu, toen], axis = 1)\n",
    "    samen.columns = ['nu', 'toen']\n",
    "    samen.fillna(0, inplace = True)\n",
    "    selfcorr[party] = cosine_similarity([samen['nu']], [samen['toen']])[0][0] * 100\n",
    "\n",
    "consistency = pd.DataFrame.from_dict(selfcorr, orient = 'index', columns = ['Consistentie']).round(2)\n",
    "consistency.sort_values(by = 'Consistentie', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = pd.DataFrame((cosy - cosy_h), columns = cosy_h.columns, index = cosy_h.index)\n",
    "\n",
    "transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overzichtstabel per partij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allemaal = allemaal_totaal.drop('Totaal', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = dict()\n",
    "for party in allemaal.columns:\n",
    "    freqs = allemaal[f'{party}']\n",
    "    div[f'{party}'] = {'Aantal woorden' : freqs.sum(),\n",
    "                     'Unieke woorden' : len([f for f in freqs if f != 0]),\n",
    "                     'Gem. frequentie' : round(freqs.sum() / len([f for f in freqs if f != 0]), 2)\n",
    "                      }\n",
    "\n",
    "for party in allemaal.columns:\n",
    "    div[party].update({\n",
    "        \"Gem. overeenkomst\" : round(np.mean(cosy[party].drop(party)), 2),\n",
    "        'Consistentie' : round(consistency['Consistentie'][party], 2)\n",
    "    })\n",
    "    \n",
    "party_stats = pd.DataFrame.from_dict(div).T\n",
    "\n",
    "party_stats = party_stats.sort_values(by = 'Gem. overeenkomst', ascending = False)\n",
    "\n",
    "trans = pd.DataFrame(pd.Series({party : round(np.median(transitions[party].drop(party)), 2) for party in transitions.index}, name = 'Transitie (med.)'))\n",
    "party_stats = pd.concat([party_stats, trans], axis = 1)\n",
    "\n",
    "party_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###2017\n",
    "div = dict()\n",
    "for partij in histo_totaal.columns:\n",
    "    freqs = histo_totaal[f'{partij}']\n",
    "    div[f'{partij}'] = {'Aantal woorden' : freqs.sum(),\n",
    "                     'Unieke woorden' : len([f for f in freqs if f != 0]),\n",
    "                     'Gem. frequentie' : freqs.sum() / len([f for f in freqs if f != 0]),\n",
    "                       }\n",
    "    \n",
    "for party in allemaal.columns:\n",
    "    div[party].update({\n",
    "        \"Gem. overeenkomst '17\" : round(np.mean(cosy_h[party].drop(party)), 2),\n",
    "    })\n",
    "\n",
    "party_stats17 = pd.DataFrame.from_dict(div).T.fillna('-')\n",
    "\n",
    "party_stats17 = party_stats17.sort_values(by = 'Gem. frequentie', ascending = False)\n",
    "party_stats17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outf = 'results/terugblik'\n",
    "#os.mkdir('results/terugblik')\n",
    "\n",
    "histo_totaal.convert_dtypes()\n",
    "with open(f'{outf}/frequencies17.csv', 'w', encoding = 'utf-8') as outfile:\n",
    "    histo_totaal.to_csv(outfile, line_terminator='\\n', decimal=',')\n",
    "    \n",
    "with open(f'{outf}/fractions17.csv', 'w', encoding = 'utf-8') as outfile:\n",
    "    histo_frac.to_csv(outfile, line_terminator='\\n', decimal=',')\n",
    "\n",
    "with open(f'{outf}/consistency.csv', 'w', encoding = 'utf-8') as outfile:\n",
    "    consistency.to_csv(outfile, line_terminator='\\n', decimal=',')\n",
    "    \n",
    "with open(f'{outf}/cosines17.csv', 'w', encoding = 'utf-8') as outfile:\n",
    "    cosy_h.to_csv(outfile, line_terminator='\\n', decimal=',')\n",
    "\n",
    "with open(f'{outf}/transitions.csv', 'w', encoding = 'utf-8') as outfile:\n",
    "    transitions.to_csv(outfile, line_terminator='\\n', decimal=',')\n",
    "    \n",
    "with open(f'{outf}/partystats17.csv', 'w', encoding = 'utf-8') as outfile:\n",
    "    party_stats17.to_csv(outfile, line_terminator='\\n', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write outcomes\n",
    "#os.mkdir('poly-stats')\n",
    "\n",
    "outf = 'results'\n",
    "\n",
    "with open(f'{outf}/fractions.csv', 'w', encoding = 'utf-8') as outfile:\n",
    "    fractions.to_csv(outfile, line_terminator = '\\n', decimal = ',')\n",
    "\n",
    "with open(f'{outf}/freqs-overzicht.csv', 'w', encoding = 'utf-8') as outfile:\n",
    "    party_stats.to_csv(outfile, line_terminator = '\\n', decimal = ',') \n",
    "    \n",
    "with open(f'{outf}/wordcounts.csv', 'w', encoding = 'utf-8') as outfile:\n",
    "    allemaal_totaal.to_csv(outfile, line_terminator = '\\n', decimal = ',')\n",
    "\n",
    "with open(f'{outf}/cosine.csv', 'w', encoding = 'utf-8') as outfile:\n",
    "    cosy.to_csv(outfile, line_terminator = '\\n', decimal = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LaTeX export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('results/tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outf = 'results/tex'\n",
    "\n",
    "with open(f'{outf}/fractions.tex', 'w', encoding = 'utf-8') as outfile:\n",
    "    fractions.to_latex(outfile, decimal = ',')\n",
    "\n",
    "with open(f'{outf}/freqs-overzicht.tex', 'w', encoding = 'utf-8') as outfile:\n",
    "    party_stats.to_latex(outfile, decimal = ',') \n",
    "    \n",
    "with open(f'{outf}/wordcounts.tex', 'w', encoding = 'utf-8') as outfile:\n",
    "    allemaal_totaal.to_latex(outfile, decimal = ',')\n",
    "\n",
    "with open(f'{outf}/cosine.tex', 'w', encoding = 'utf-8') as outfile:\n",
    "    cosy.to_latex(outfile, decimal = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outf = 'results/tex/histo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{outf}/frequencies17.tex', 'w', encoding = 'utf-8') as outfile:\n",
    "    histo_totaal.to_latex(outfile, decimal=',')\n",
    "    \n",
    "with open(f'{outf}/fractions17.tex', 'w', encoding = 'utf-8') as outfile:\n",
    "    histo_frac.to_latex(outfile, decimal=',')\n",
    "\n",
    "with open(f'{outf}/consistency.tex', 'w', encoding = 'utf-8') as outfile:\n",
    "    consistency.to_latex(outfile, decimal=',')\n",
    "    \n",
    "with open(f'{outf}/cosines17.tex', 'w', encoding = 'utf-8') as outfile:\n",
    "    cosy_h.to_latex(outfile, decimal=',')\n",
    "\n",
    "with open(f'{outf}/transitions.tex', 'w', encoding = 'utf-8') as outfile:\n",
    "    transitions.to_latex(outfile, decimal=',')\n",
    "    \n",
    "with open(f'{outf}/partystats17.tex', 'w', encoding = 'utf-8') as outfile:\n",
    "    party_stats17.to_latex(outfile, decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load results from previous iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infol = 'results'\n",
    "\n",
    "with open(f'{infol}/fractions.csv', 'r', encoding = 'utf-8') as infile:\n",
    "    fractions = pd.read_csv(infile, index_col = 0, decimal = ',')\n",
    "\n",
    "with open(f'{infol}/freqs-overzicht.csv', 'r', encoding = 'utf-8') as infile:\n",
    "    party_stats = pd.read_csv(infile, index_col = 0, decimal = ',') \n",
    "    \n",
    "with open(f'{infol}/wordcounts.csv', 'r', encoding = 'utf-8') as infile:\n",
    "    allemaal_totaal = pd.read_csv(infile, index_col = 0, decimal = ',')\n",
    "\n",
    "with open(f'{infol}/cosine.csv', 'r', encoding = 'utf-8') as infile:\n",
    "    cosy = pd.read_csv(infile, index_col = 0, decimal = ',')\n",
    "\n",
    "infol = 'results/terugblik'\n",
    "#os.mkdir('results/terugblik')\n",
    "\n",
    "\n",
    "with open(f'{infol}/frequencies17.csv', 'r', encoding = 'utf-8') as infile:\n",
    "    histo_totaal = pd.read_csv(infile, index_col = 0, decimal = ',')\n",
    "    \n",
    "with open(f'{infol}/fractions17.csv', 'r', encoding = 'utf-8') as infile:\n",
    "    histo_frac = pd.read_csv(infile, index_col = 0, decimal = ',')\n",
    "\n",
    "with open(f'{infol}/consistency.csv', 'r', encoding = 'utf-8') as infile:\n",
    "    consistency = pd.read_csv(infile, index_col = 0, decimal = ',')\n",
    "    \n",
    "with open(f'{infol}/cosines17.csv', 'r', encoding = 'utf-8') as infile:\n",
    "    cosy_h = pd.read_csv(infile, index_col = 0, decimal = ',')\n",
    "\n",
    "with open(f'{infol}/transitions.csv', 'r', encoding = 'utf-8') as infile:\n",
    "    transitions = pd.read_csv(infile, index_col = 0, decimal = ',')\n",
    "    \n",
    "with open(f'{infol}/partystats17.csv', 'r', encoding = 'utf-8') as infile:\n",
    "    party_stats17 = pd.read_csv(infile, index_col = 0, decimal = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotty time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_colors_dict = {'50plus' : '#93107e',\n",
    "               'cda' :  '#027a60',\n",
    "               'cu' : '#008acc',\n",
    "               'd66' : '#00ae41',\n",
    "               'denk' : '#00b7b2',\n",
    "               'fvd' : '#6f2422',\n",
    "               'gl' : '#39a935',\n",
    "               'pvda' : '#df111a',\n",
    "               'pvdd' : '#006b2d',\n",
    "               'pvv' : '#012758',\n",
    "               'sgp' : '#ea5b0b',\n",
    "               'sp' : '#ec1b23',\n",
    "               'vvd' : '#0a2cca'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency = consistency.sort_values('Consistentie', ascending=False)\n",
    "height = list(consistency['Consistentie'])\n",
    "bars = tuple(consistency.index)\n",
    "y_pos = np.arange(len(bars))\n",
    "error = 0.1 * y_pos\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "plt.bar(y_pos, height, color=[party_colors_dict[party.lower()] for party in consistency.index])\n",
    "plt.yticks([y * 10 for y in range(11)])\n",
    "plt.xticks(y_pos, bars)\n",
    "ax.set_axisbelow(True)\n",
    "#ax.errorbar(bars, y_pos, yerr=error, fmt='-o')\n",
    "plt.grid(axis='y')\n",
    "#plt.title('Consistentie vocabulaire (t.o.v. 2017)', size = 12)\n",
    "#plt.errorbar(bars, height)\n",
    "plt.savefig('images/consistentie.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overeenkomsten = party_stats['Gem. overeenkomst'].drop('Totaal').sort_values(ascending=False).convert_dtypes()\n",
    "height = [float(y) for y in list(overeenkomsten)]\n",
    "bars = tuple(overeenkomsten.index)\n",
    "y_pos = np.arange(len(bars))\n",
    "error = 0.1 * y_pos\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "plt.bar(y_pos, height, color=[party_colors_dict[party.lower()] for party in overeenkomsten.index])\n",
    "plt.yticks([y * 10 for y in range(11)])\n",
    "plt.xticks(y_pos, bars)\n",
    "ax.set_axisbelow(True)\n",
    "#ax.errorbar(bars, y_pos, yerr=error, fmt='-o')\n",
    "plt.grid(axis='y')\n",
    "#plt.title('Gem. overeenkomst vocabulaire met overige partijen', size = 12)\n",
    "#plt.errorbar(bars, height)\n",
    "plt.savefig('images/gem_overeenkomst.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = np.array(cosy)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12.5, 12.5))\n",
    "ax.imshow(cosy, cmap=plt.cm.RdYlGn, alpha=.6)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=str(conf_matrix[i, j].round(1)) + '%', va='center', ha='center', size='large')\n",
    "        \n",
    "plt.xticks(ticks = [x for x in range(conf_matrix.shape[0])], labels = list(cosy.index))\n",
    "plt.yticks(ticks = [y for y in range(conf_matrix.shape[1])], labels = list(cosy.columns))\n",
    "#plt.title('Mate van overeenkomstigheid \\n', fontsize=18)\n",
    "plt.savefig('images/mate-van-overeenkomstigheid.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = np.array(transitions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12.5, 12.5))\n",
    "ax.imshow(transitions, cmap=plt.cm.RdYlGn, alpha=.6)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=str(conf_matrix[i, j].round(1)) + 'pp', va='center', ha='center', size='large')\n",
    "        \n",
    "plt.xticks(ticks = [x for x in range(conf_matrix.shape[0])], labels = list(cosy.index))\n",
    "plt.yticks(ticks = [y for y in range(conf_matrix.shape[1])], labels = list(cosy.columns))\n",
    "#plt.title('Verschuiving qua mate van overeenkomstigheid \\n', fontsize=18)\n",
    "plt.savefig('images/verschuiving-overeenkomstigheid.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simdict = {p: {'Partij' : q, 'Gelijkenis' : round(max(cosy[p].drop(p)),1)} for p in cosy.columns for q in cosy.index if max(cosy[p].drop(p)) == cosy[p][q]}\n",
    "\n",
    "simdict2 = {p: {\"Partij ('17)\" : q, \"Gelijkenis ('17)\" : round(max(cosy_h[p].drop(p)),1)} for p in cosy_h.columns for q in cosy_h.index if max(cosy_h[p].drop(p)) == cosy_h[p][q]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(simdict).T\n",
    "df2 = pd.DataFrame(simdict2).T\n",
    "\n",
    "buren = pd.concat([df1,df2], axis=1).convert_dtypes()\n",
    "\n",
    "buren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buren.to_latex('results/tex/buren.tex', decimal = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg cosine sim\n",
    "\n",
    "round(np.mean(np.mean([cosy[party].drop(party) for party in cosy.index])), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std. cosine sim\n",
    "\n",
    "np.std(np.array([cosy[party].drop(party) for party in cosy.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = transitions.drop('PVV').drop('PVV', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(np.array([transitions[party].drop(party) for party in transitions.index])),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(np.array([t[party].drop(party) for party in t.index])), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(transitions['PVV'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
